{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:/Users/dell/Desktop/mnist/train.csv\").values\n",
    "test  = pd.read_csv(\"C:/Users/dell/Desktop/mnist/test.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data  = train[:, 1:].reshape(train.shape[0], 1, 28, 28) # 从第一列开始读取, 并reshape成(4200,1,28,28)\n",
    "X_data  = X_data.astype(float)\n",
    "X_data /= 255.0                                           # 归一化\n",
    "X_data  = torch.from_numpy(X_data);                       # 转换成tensor类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_label = train[:,0];                                     # label在第零列, 所以读取第零列\n",
    "X_label = X_label.astype(int);\n",
    "X_label = torch.from_numpy(X_label);\n",
    "X_label = X_label.view(train.shape[0],-1);               # 从[42000]变为 [42000,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42000, 1, 28, 28]) torch.Size([42000, 1])\n"
     ]
    }
   ],
   "source": [
    "print (X_data.size(), X_label.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistNet(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2_drop): Dropout2d(p=0.2)\n",
      "  (fc1): Linear(in_features=128, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "USE GPU\n"
     ]
    }
   ],
   "source": [
    "class MnistNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(5,5))\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(5,5))\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2_drop = nn.Dropout2d(p = 0.2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(3,3))\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=(3,3))\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=(3,3))\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=(1,1))\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        ###\n",
    "        x = self.bn2(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv2_drop(x)\n",
    "        ###\n",
    "        # x = self.conv2_drop(F.max_pool2d(self.bn2(x),2))\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.bn4(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.bn5(x)\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.bn6(x)\n",
    "        size =  x.size()[1]*x.size()[2]*x.size()[3]\n",
    "        #print(size)\n",
    "        x = x.view(-1, size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "pass\n",
    "\n",
    "net = MnistNet()\n",
    "\n",
    "print(net)\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "\tnet = net.cuda()\n",
    "\tprint ('USE GPU')\n",
    "else:\n",
    "\tprint ('USE CPU')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.3, momentum = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Training phase\n"
     ]
    }
   ],
   "source": [
    "print (\"3. Training phase\")\n",
    "nb_train = train.shape[0]\n",
    "nb_epoch = 5\n",
    "nb_index = 0\n",
    "nb_batch = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, Loss = 0.065264\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nb_epoch):\n",
    "    if nb_index + nb_batch >= nb_train:          # 创造读取的mini_batch的index, 当大于整个数据集的size时(42000), index归零\n",
    "        nb_index = 0\n",
    "    else:\n",
    "        nb_index += nb_batch                     # 这里不应该时epoch, 而是iteration, 因为一次循环只训练一个mini_batch\n",
    "\n",
    "    mini_data  = Variable(X_data[nb_index:(nb_index+nb_batch)].clone())     # 读取一个minibatch size的data\n",
    "    mini_label = Variable(X_label[nb_index:(nb_index+nb_batch)].clone(), requires_grad = False)\n",
    "    mini_data  = mini_data.type(torch.FloatTensor)                          # 需要进行类型的转换, 不然计算loss时候会出错\n",
    "    mini_label = mini_label.type(torch.LongTensor)\n",
    "    if use_gpu:\n",
    "        mini_data  = mini_data.cuda()\n",
    "        mini_label = mini_label.cuda()\n",
    "    optimizer.zero_grad()\n",
    "    mini_out   = net(mini_data)\n",
    "    mini_label = mini_label.view(nb_batch)\n",
    "    mini_loss  = criterion(mini_out, mini_label)\n",
    "    mini_loss.backward()\n",
    "    optimizer.step() \n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(\"Epoch = %d, Loss = %f\" %(epoch+1, mini_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  = pd.read_csv(\"C:/Users/dell/Desktop/mnist/test.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chamge = test[0:100][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_chamge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Testing phase\n",
      "torch.Size([100, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print (\"4. Testing phase\")\n",
    "\n",
    "Y_data  = test_chamge.reshape(test_chamge.shape[0], 1, 28, 28)\n",
    "Y_data  = Y_data.astype(float)\n",
    "Y_data /= 255.0\n",
    "Y_data  = torch.from_numpy(Y_data)\n",
    "print (Y_data.size())\n",
    "nb_test = test_chamge.shape[0]\n",
    "\n",
    "net.eval()\n",
    "\n",
    "final_prediction = np.ndarray(shape = (nb_test, 2), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tested = 10\n",
      "Total tested = 20\n",
      "Total tested = 30\n",
      "Total tested = 40\n",
      "Total tested = 50\n",
      "Total tested = 60\n",
      "Total tested = 70\n",
      "Total tested = 80\n",
      "Total tested = 90\n",
      "Total tested = 100\n"
     ]
    }
   ],
   "source": [
    "for each_sample in range(nb_test):\n",
    "\tsample_data = Variable(Y_data[each_sample:each_sample+1].clone())\n",
    "\tsample_data = sample_data.type(torch.FloatTensor)\n",
    "\tif use_gpu:\n",
    "\t\tsample_data = sample_data.cuda()\n",
    "\tsample_out = net(sample_data)\n",
    "\tpred = torch.max(sample_out, 1)                         # 找出out里面的最大值, 以及其index \n",
    "\tfinal_prediction[each_sample][0] = 1 + each_sample      # 最终结果的第0列是index\n",
    "\tfinal_prediction[each_sample][1] = pred[1][0]           # 第1列是预测结果, out里面的最大值的index \n",
    "\tif (each_sample + 1) % 10 == 0:\n",
    "\t\tprint(\"Total tested = %d\" %(each_sample + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0503, -2.0340, -0.9220, -1.7652,  7.7914,  0.3642,  0.9878, -1.6955,\n",
       "         -0.6362,  0.3033]], device='cuda:0', grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7.7914], device='cuda:0', grad_fn=<MaxBackward0>),\n",
       " tensor([4], device='cuda:0'))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('5. Generating submission file')\n",
    "\n",
    "submission = pd.DataFrame(final_prediction, dtype=int, columns=['ImageId', 'Label'])\n",
    "submission.to_csv('C:/Users/dell/Desktop/mnist/submission.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   2],\n",
       "       [  2,   0],\n",
       "       [  3,   9],\n",
       "       [  4,   9],\n",
       "       [  5,   3],\n",
       "       [  6,   7],\n",
       "       [  7,   0],\n",
       "       [  8,   3],\n",
       "       [  9,   0],\n",
       "       [ 10,   3],\n",
       "       [ 11,   5],\n",
       "       [ 12,   7],\n",
       "       [ 13,   4],\n",
       "       [ 14,   0],\n",
       "       [ 15,   4],\n",
       "       [ 16,   3],\n",
       "       [ 17,   3],\n",
       "       [ 18,   1],\n",
       "       [ 19,   9],\n",
       "       [ 20,   0],\n",
       "       [ 21,   9],\n",
       "       [ 22,   1],\n",
       "       [ 23,   1],\n",
       "       [ 24,   5],\n",
       "       [ 25,   7],\n",
       "       [ 26,   4],\n",
       "       [ 27,   2],\n",
       "       [ 28,   7],\n",
       "       [ 29,   4],\n",
       "       [ 30,   7],\n",
       "       [ 31,   7],\n",
       "       [ 32,   5],\n",
       "       [ 33,   4],\n",
       "       [ 34,   2],\n",
       "       [ 35,   6],\n",
       "       [ 36,   2],\n",
       "       [ 37,   5],\n",
       "       [ 38,   5],\n",
       "       [ 39,   1],\n",
       "       [ 40,   6],\n",
       "       [ 41,   7],\n",
       "       [ 42,   7],\n",
       "       [ 43,   4],\n",
       "       [ 44,   9],\n",
       "       [ 45,   8],\n",
       "       [ 46,   7],\n",
       "       [ 47,   8],\n",
       "       [ 48,   2],\n",
       "       [ 49,   6],\n",
       "       [ 50,   7],\n",
       "       [ 51,   6],\n",
       "       [ 52,   8],\n",
       "       [ 53,   8],\n",
       "       [ 54,   3],\n",
       "       [ 55,   8],\n",
       "       [ 56,   2],\n",
       "       [ 57,   1],\n",
       "       [ 58,   2],\n",
       "       [ 59,   2],\n",
       "       [ 60,   5],\n",
       "       [ 61,   4],\n",
       "       [ 62,   1],\n",
       "       [ 63,   7],\n",
       "       [ 64,   0],\n",
       "       [ 65,   0],\n",
       "       [ 66,   0],\n",
       "       [ 67,   1],\n",
       "       [ 68,   9],\n",
       "       [ 69,   0],\n",
       "       [ 70,   1],\n",
       "       [ 71,   6],\n",
       "       [ 72,   5],\n",
       "       [ 73,   8],\n",
       "       [ 74,   8],\n",
       "       [ 75,   2],\n",
       "       [ 76,   8],\n",
       "       [ 77,   9],\n",
       "       [ 78,   9],\n",
       "       [ 79,   2],\n",
       "       [ 80,   3],\n",
       "       [ 81,   5],\n",
       "       [ 82,   4],\n",
       "       [ 83,   1],\n",
       "       [ 84,   0],\n",
       "       [ 85,   9],\n",
       "       [ 86,   2],\n",
       "       [ 87,   4],\n",
       "       [ 88,   3],\n",
       "       [ 89,   6],\n",
       "       [ 90,   7],\n",
       "       [ 91,   2],\n",
       "       [ 92,   0],\n",
       "       [ 93,   6],\n",
       "       [ 94,   6],\n",
       "       [ 95,   1],\n",
       "       [ 96,   4],\n",
       "       [ 97,   3],\n",
       "       [ 98,   9],\n",
       "       [ 99,   7],\n",
       "       [100,   4]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
