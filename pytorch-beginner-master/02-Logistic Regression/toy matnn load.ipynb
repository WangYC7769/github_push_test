{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import time\n",
    "# 定义超参数\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "num_epoches = 20\n",
    "\n",
    "# 下载训练集 MNIST 手写数字训练集\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\"\"\"\n",
    "class Logstic_Regression1(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(Logstic_Regression1, self).__init__()\n",
    "        self.logstic = nn.Linear(in_dim, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.logstic(x)\n",
    "        return out    \n",
    "\"\"\"\n",
    "#model = Logstic_Regression1(28*28, 10)\n",
    "\n",
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(784, 10),\n",
    "    # torch.nn.ReLU(),\n",
    "    torch.nn.Linear(10, 10)\n",
    ")\n",
    "\n",
    "parameters_all = net2.state_dict() \n",
    "parameters_1 = torch.load('logstic_model1.pth')\n",
    "parameters_3 = torch.load('logstic_model3.pth')\n",
    "# model.load_state_dict(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 0.0304,  0.0145,  0.0322,  ..., -0.0154,  0.0072, -0.0085],\n",
       "                      [ 0.0060, -0.0125,  0.0065,  ...,  0.0152,  0.0146,  0.0299],\n",
       "                      [-0.0164, -0.0085,  0.0124,  ..., -0.0243,  0.0318, -0.0233],\n",
       "                      ...,\n",
       "                      [-0.0301, -0.0075, -0.0152,  ...,  0.0106, -0.0026,  0.0052],\n",
       "                      [-0.0223,  0.0323, -0.0221,  ..., -0.0040,  0.0030,  0.0323],\n",
       "                      [-0.0159, -0.0190, -0.0164,  ...,  0.0157,  0.0016, -0.0050]])),\n",
       "             ('0.bias',\n",
       "              tensor([-0.0739,  0.1572, -0.0433, -0.0935,  0.0564,  0.2139, -0.0080,  0.1060,\n",
       "                      -0.3302, -0.0264]))])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_1['0.weight'] = parameters_1.pop('logstic.weight')\n",
    "parameters_1['0.bias'] = parameters_1.pop('logstic.bias')\n",
    "parameters_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('1.weight',\n",
       "              tensor([[ 1.2153, -0.1210,  0.0188, -0.0128, -0.0109,  0.1356,  0.0371,  0.2003,\n",
       "                       -0.0087, -0.0840],\n",
       "                      [-0.4054,  1.1147, -0.2494, -0.2564, -0.1963, -0.3948, -0.1654, -0.1669,\n",
       "                       -0.1895, -0.2892],\n",
       "                      [-0.3155, -0.2631,  1.1549, -0.1747, -0.3102, -0.4532, -0.1536, -0.2037,\n",
       "                       -0.0926, -0.2224],\n",
       "                      [-0.2498, -0.1537,  0.0293,  1.1062, -0.3516, -0.1344, -0.2632, -0.0410,\n",
       "                       -0.2375,  0.0487],\n",
       "                      [-0.4075, -0.1133, -0.1944, -0.3503,  1.1443, -0.0404, -0.0228, -0.1564,\n",
       "                       -0.2146,  0.1121],\n",
       "                      [-0.1851, -0.2274, -0.3904, -0.2392, -0.2042,  0.9863, -0.1618, -0.1579,\n",
       "                       -0.0295, -0.2748],\n",
       "                      [-0.1500,  0.0925, -0.0252, -0.3781,  0.1047, -0.0215,  1.2224, -0.2020,\n",
       "                       -0.2250, -0.2325],\n",
       "                      [-0.1622, -0.0311, -0.2437, -0.0715, -0.1862, -0.4009, -0.2972,  1.3107,\n",
       "                       -0.4221,  0.1608],\n",
       "                      [-0.2697, -0.1220,  0.0098, -0.1958, -0.1610, -0.0182, -0.2016, -0.1612,\n",
       "                        1.1635,  0.0713],\n",
       "                      [-0.2863, -0.1922, -0.3069, -0.1370, -0.1105, -0.3943, -0.1598,  0.1132,\n",
       "                       -0.0339,  1.1247]])),\n",
       "             ('1.bias',\n",
       "              tensor([-0.2648, -0.2342, -0.2020,  0.1374, -0.3356,  0.1539,  0.0269,  0.0159,\n",
       "                      -0.0350,  0.0662]))])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_1['0.weight'] = parameters_1.pop('logstic.weight')\n",
    "parameters_1['0.bias'] = parameters_1.pop('logstic.bias')\n",
    "parameters_3['1.weight'] = parameters_3.pop('logstic.weight')\n",
    "parameters_3['1.bias'] = parameters_3.pop('logstic.bias')\n",
    "parameters_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(parameters_all['0.weight'].size())\n",
    "print(parameters_all['0.bias'].size())\n",
    "print(parameters_all['1.weight'].size())\n",
    "print(parameters_all['1.bias'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(parameters_1['0.weight'].size())\n",
    "print(parameters_1['0.bias'].size())\n",
    "print(parameters_3['1.weight'].size())\n",
    "print(parameters_3['1.bias'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_all = parameters_1.copy()\n",
    "parameters_all.update(parameters_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2.load_state_dict(parameters_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 1.weight: copying a param of torch.Size([1, 10]) from checkpoint, where the shape is torch.Size([10, 10]) in current model.\n\tsize mismatch for 1.bias: copying a param of torch.Size([1]) from checkpoint, where the shape is torch.Size([10]) in current model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-619cd86fdc77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m    717\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m--> 719\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 1.weight: copying a param of torch.Size([1, 10]) from checkpoint, where the shape is torch.Size([10, 10]) in current model.\n\tsize mismatch for 1.bias: copying a param of torch.Size([1]) from checkpoint, where the shape is torch.Size([10]) in current model."
     ]
    }
   ],
   "source": [
    "net2.load_state_dict(parameters_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'logstic.weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-eb1dfa243a33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logstic.weight'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'logstic.weight'"
     ]
    }
   ],
   "source": [
    "print(parameters_1['logstic.weight'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(parameters_3['logstic.bias'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n"
     ]
    }
   ],
   "source": [
    "print(parameters_all['0.weight'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "print(parameters_all['1.weight'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('logstic.weight',\n",
       "              tensor([[ 0.0304,  0.0145,  0.0322,  ..., -0.0154,  0.0072, -0.0085],\n",
       "                      [ 0.0060, -0.0125,  0.0065,  ...,  0.0152,  0.0146,  0.0299],\n",
       "                      [-0.0164, -0.0085,  0.0124,  ..., -0.0243,  0.0318, -0.0233],\n",
       "                      ...,\n",
       "                      [-0.0301, -0.0075, -0.0152,  ...,  0.0106, -0.0026,  0.0052],\n",
       "                      [-0.0223,  0.0323, -0.0221,  ..., -0.0040,  0.0030,  0.0323],\n",
       "                      [-0.0159, -0.0190, -0.0164,  ...,  0.0157,  0.0016, -0.0050]])),\n",
       "             ('logstic.bias',\n",
       "              tensor([-0.0739,  0.1572, -0.0433, -0.0935,  0.0564,  0.2139, -0.0080,  0.1060,\n",
       "                      -0.3302, -0.0264]))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.0066, -0.0131,  0.0076,  ...,  0.0319,  0.0002, -0.0245],\n",
       "                      [-0.0267,  0.0295, -0.0020,  ...,  0.0014, -0.0201,  0.0000],\n",
       "                      [ 0.0051, -0.0321, -0.0297,  ..., -0.0203,  0.0216, -0.0002],\n",
       "                      ...,\n",
       "                      [ 0.0173,  0.0011,  0.0236,  ...,  0.0246,  0.0232, -0.0014],\n",
       "                      [-0.0253,  0.0286,  0.0056,  ..., -0.0246,  0.0093,  0.0287],\n",
       "                      [ 0.0321,  0.0271, -0.0255,  ...,  0.0004,  0.0324, -0.0306]])),\n",
       "             ('0.bias',\n",
       "              tensor([-0.0176,  0.0054, -0.0268,  0.0326,  0.0134, -0.0285, -0.0163,  0.0122,\n",
       "                       0.0146, -0.0165])),\n",
       "             ('1.weight',\n",
       "              tensor([[-0.1478,  0.2805,  0.2750,  0.1247, -0.1853,  0.1047,  0.1696,  0.0236,\n",
       "                        0.2315, -0.2906]])),\n",
       "             ('1.bias', tensor([0.1847]))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 100, 'b': 200}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'a': 100} \n",
    "a['b'] = 200 \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 100, 'b': 200, '0.a_b': 100}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"0.a_b\"] = a[\"a\"]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.pop('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 200, '0.a_b': 100}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 200, '0.a_b': 100}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['0.a_b'] = a.pop('a')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.dic': 2, 'A': 1}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.update(A = a.pop('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-100-e414a2df63cb>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-100-e414a2df63cb>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    0.dic = a.pop('a')\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "0.dic = a.pop('a')\n",
    "a.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-101-9be9f2a420b3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-101-9be9f2a420b3>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    0.asd = 1\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "0.asd = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
