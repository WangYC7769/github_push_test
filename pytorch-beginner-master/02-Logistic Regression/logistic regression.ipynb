{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import time\n",
    "# 定义超参数\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "num_epoches = 100\n",
    "\n",
    "# 下载训练集 MNIST 手写数字训练集\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: ./data\n",
       "    Transforms (if any): ToTensor()\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x27626354358>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logstic_Regression(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(Logstic_Regression, self).__init__()\n",
    "        self.logstic = nn.Linear(in_dim, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.logstic(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = Logstic_Regression(28 * 28, 10)  # 图片大小是28x28\n",
    "use_gpu = torch.cuda.is_available()  # 判断是否有GPU加速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Logstic_Regression(\n",
       "  (logstic): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1b74ea50908>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader, 1):\n",
    "    img, label = data                # data[0].size()=32,1,28,28  data[1].size()=32\n",
    "    img = img.view(img.size(0), -1)  # 将图片展开成 28x28 , img.size() = 32*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Variable(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 6, 8, 9, 9, 3, 1, 2, 5, 3, 1, 3, 8, 3, 0, 1, 8, 0, 8, 2, 3, 4, 5, 9,\n",
      "        5, 1, 3, 3, 3, 4, 5, 0])\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n",
      "torch.Size([32, 784])\n"
     ]
    }
   ],
   "source": [
    "print(label.size())\n",
    "print(img.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]]), tensor([1, 6, 8, 9, 9, 3, 1, 2, 5, 3, 1, 3, 8, 3, 0, 1, 8, 0, 8, 2, 3, 4, 5, 9,\n",
      "        5, 1, 3, 3, 3, 4, 5, 0])] \n",
      "\n",
      "torch.Size([32, 1, 28, 28]) \n",
      "\n",
      "torch.Size([32]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data,'\\n')\n",
    "print(data[0].size(),'\\n')\n",
    "print(data[1].size(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'use_gpu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5c823d064251>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 定义loss和optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'use_gpu' is not defined"
     ]
    }
   ],
   "source": [
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "# 定义loss和optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 开始训练\n",
    "#for epoch in range(num_epoches):\n",
    "for epoch in range(1):\n",
    "    print('*' * 10)\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    since = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)  # 将图片展开成 28x28\n",
    "        if use_gpu:\n",
    "            img = Variable(img).cuda()\n",
    "            label = Variable(label).cuda()\n",
    "        else:\n",
    "            img = Variable(img)\n",
    "            label = Variable(label)\n",
    "        # 向前传播\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.data[0] * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        running_acc += num_correct.data[0]\n",
    "        # 向后传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 300 == 0:\n",
    "            print('[{}/{}] Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "                epoch + 1, num_epoches, running_loss / (batch_size * i),\n",
    "                running_acc * 100 / (batch_size * i)))\n",
    "    print('Finish {} epoch, Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "        epoch + 1, running_loss / (len(train_dataset)), running_acc *100 / (len(\n",
    "            train_dataset))))\n",
    "    model.eval()\n",
    "    eval_loss = 0.\n",
    "    eval_acc = 0.\n",
    "    for data in test_loader:\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        if use_gpu:\n",
    "            img = Variable(img, volatile=True).cuda()\n",
    "            label = Variable(label, volatile=True).cuda()\n",
    "        else:\n",
    "            img = Variable(img, volatile=True)\n",
    "            label = Variable(label, volatile=True)\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        eval_loss += loss.data[0] * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        eval_acc += num_correct.data[0]\n",
    "    print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(\n",
    "        test_dataset)), eval_acc / (len(test_dataset))))\n",
    "    print('Time:{:.1f} s'.format(time.time() - since))\n",
    "    print()\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), './logstic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'SherlockLiao'\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import time\n",
    "# 定义超参数\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "num_epoches = 100\n",
    "\n",
    "# 下载训练集 MNIST 手写数字训练集\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# 定义 Logistic Regression 模型\n",
    "\"\"\"\n",
    "class Logstic_Regression(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(Logstic_Regression, self).__init__()\n",
    "        #self.logstic = nn.Linear(in_dim, n_class)\n",
    "        self.test = nn.Linear(in_dim, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.test(x)\n",
    "        return out\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "class Logstic_Regression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Logstic_Regression, self).__init__()\n",
    "        #self.logstic = nn.Linear(in_dim, n_class)\n",
    "        self.test = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.test(x)\n",
    "        return out\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Logstic_Regression(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(Logstic_Regression, self).__init__()\n",
    "        #self.logstic = nn.Linear(in_dim, n_class)\n",
    "        self.test = nn.Linear(in_dim, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.test(x)\n",
    "        out = F.sigmoid(x)\n",
    "        return out\n",
    "\n",
    "model = Logstic_Regression(28*28, 10)  # 图片大小是28x28\n",
    "#use_gpu = torch.cuda.is_available()  # 判断是否有GPU加速\n",
    "use_gpu = False\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "# 定义loss和optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.FloatTensor but found type torch.LongTensor for argument #2 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ba98e61bf516>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# 向前传播\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   1714\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1716\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pointwise_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_pointwise_loss\u001b[1;34m(lambd, lambd_optimized, input, target, reduction)\u001b[0m\n\u001b[0;32m   1672\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'elementwise_mean'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1673\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1674\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlambd_optimized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of type torch.FloatTensor but found type torch.LongTensor for argument #2 'target'"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "#for epoch in range(num_epoches):\n",
    "for epoch in range(5):\n",
    "    print('*' * 10)\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    since = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        img, label = data                # data[0].size()=32,1,28,28  data[1].size()=32\n",
    "        img = img.view(img.size(0), -1)  # 将图片展开成 28x28 , 32*784\n",
    "        if use_gpu:\n",
    "            img = Variable(img).cuda()\n",
    "            label = Variable(label).cuda()\n",
    "        else:\n",
    "            img = Variable(img)\n",
    "            label = Variable(label)\n",
    "        # 向前传播\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.data[0] * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        running_acc += num_correct.data[0]\n",
    "        # 向后传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 300 == 0:\n",
    "            print('[{}/{}] Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "                epoch + 1, num_epoches, running_loss  / (batch_size * i),\n",
    "                running_acc * 100 / (batch_size * i)))\n",
    "    print('Finish {} epoch, Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "        epoch + 1, running_loss / (len(train_dataset)), running_acc * 100 / (len(\n",
    "            train_dataset))))\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss = 0.\n",
    "    eval_acc = 0.\n",
    "    for data in test_loader:\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        if use_gpu:\n",
    "            img = Variable(img, volatile=True).cuda()\n",
    "            label = Variable(label, volatile=True).cuda()\n",
    "        else:\n",
    "            img = Variable(img, volatile=True)\n",
    "            label = Variable(label, volatile=True)\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        eval_loss += loss.data[0] * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        eval_acc += num_correct.data[0]\n",
    "    print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(\n",
    "        test_dataset)), eval_acc * 100 / (len(test_dataset))))\n",
    "    print('Time:{:.1f} s'.format(time.time() - since))\n",
    "    print()\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), './logstic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'SherlockLiao'\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import time\n",
    "# 定义超参数\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "num_epoches = 100\n",
    "\n",
    "# 下载训练集 MNIST 手写数字训练集\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# 定义 Logistic Regression 模型\n",
    "\"\"\"\n",
    "class Logstic_Regression(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(Logstic_Regression, self).__init__()\n",
    "        #self.logstic = nn.Linear(in_dim, n_class)\n",
    "        self.test = nn.Linear(in_dim, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.test(x)\n",
    "        return out\n",
    "\"\"\"\n",
    "\n",
    "class Logstic_Regression(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(Logstic_Regression, self).__init__()\n",
    "        #self.logstic = nn.Linear(in_dim, n_class)\n",
    "        self.test = nn.Linear(in_dim, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.test(x)\n",
    "        out = F.sigmoid(x)\n",
    "        return out\n",
    "\n",
    "model = Logstic_Regression(28 * 28, 10)  # 图片大小是28x28\n",
    "#use_gpu = torch.cuda.is_available()  # 判断是否有GPU加速\n",
    "use_gpu = False\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "# 定义loss和optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] Loss: 1.976, Acc: 79.198\n",
      "[1/100] Loss: 1.972, Acc: 79.318\n",
      "[1/100] Loss: 1.970, Acc: 79.281\n",
      "[1/100] Loss: 1.967, Acc: 79.305\n",
      "[1/100] Loss: 1.965, Acc: 79.231\n",
      "[1/100] Loss: 1.962, Acc: 79.240\n",
      "Finish 1 epoch, Loss: 1.961, Acc: 79.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:53: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:56: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.938, Acc: 80.830\n",
      "Time:8.1 s\n",
      "\n",
      "**********\n",
      "epoch 2\n",
      "[2/100] Loss: 1.944, Acc: 79.406\n",
      "[2/100] Loss: 1.941, Acc: 79.557\n",
      "[2/100] Loss: 1.938, Acc: 79.955\n",
      "[2/100] Loss: 1.936, Acc: 80.190\n",
      "[2/100] Loss: 1.934, Acc: 80.106\n",
      "[2/100] Loss: 1.932, Acc: 80.193\n",
      "Finish 2 epoch, Loss: 1.931, Acc: 80.223\n",
      "Test Loss: 1.911, Acc: 81.340\n",
      "Time:8.3 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "#for epoch in range(num_epoches):\n",
    "for epoch in range(2):\n",
    "    print('*' * 10)\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    since = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        img, label = data                # data[0].size()=32,1,28,28  data[1].size()=32\n",
    "        img = img.view(img.size(0), -1)  # 将图片展开成 28x28 , 32*784\n",
    "        if use_gpu:\n",
    "            img = Variable(img).cuda()\n",
    "            label = Variable(label).cuda()\n",
    "        else:\n",
    "            img = Variable(img)\n",
    "            label = Variable(label)\n",
    "        # 向前传播\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.data[0] * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        running_acc += num_correct.data[0]\n",
    "        # 向后传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 300 == 0:\n",
    "            print('[{}/{}] Loss: {:.3f}, Acc: {:.3f}'.format(\n",
    "                epoch + 1, num_epoches, running_loss  / (batch_size * i),\n",
    "                float(running_acc) * 100 / (batch_size * i)))\n",
    "    print('Finish {} epoch, Loss: {:.3f}, Acc: {:.3f}'.format(\n",
    "        epoch + 1, running_loss / (len(train_dataset)), float(running_acc) * 100 / (len(\n",
    "            train_dataset))))\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss = 0.\n",
    "    eval_acc = 0.\n",
    "    for data in test_loader:\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        if use_gpu:\n",
    "            img = Variable(img, volatile=True).cuda()\n",
    "            label = Variable(label, volatile=True).cuda()\n",
    "        else:\n",
    "            img = Variable(img, volatile=True)\n",
    "            label = Variable(label, volatile=True)\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        eval_loss += loss.data[0] * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        eval_acc += num_correct.data[0]\n",
    "    print('Test Loss: {:.3f}, Acc: {:.3f}'.format(eval_loss / (len(\n",
    "        test_dataset)), float(eval_acc) * 100 / (len(test_dataset))))\n",
    "    print('Time:{:.1f} s'.format(time.time() - since))\n",
    "    print()\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), './logstic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43264.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(running_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.10666666666667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(running_acc) * 100 / (batch_size * i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n",
      "32\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "batch_size * i\n",
    "print(i)\n",
    "print(batch_size)\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] Loss: 0.605629, Acc: 86.000000\n"
     ]
    }
   ],
   "source": [
    "print('[{}/{}] Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "                epoch + 1, num_epoches, running_loss / (batch_size * i),\n",
    "                running_acc * 100 / (batch_size * i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(27)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.4354, 1.8158, 2.8642, 2.3265, 4.3354, 1.9226, 3.4508, 2.3127, 0.8361,\n",
       "         3.0646, 4.3123, 3.7371, 1.4075, 1.2359, 3.4304, 2.6911, 1.3671, 3.1406,\n",
       "         2.0034, 3.4352, 2.6527, 1.4568, 4.8898, 3.9453, 2.8083, 2.4804, 2.4915,\n",
       "         1.0021, 0.8441, 3.1524, 2.6410, 2.0503], grad_fn=<MaxBackward0>),\n",
       " tensor([2, 8, 4, 8, 2, 5, 0, 3, 4, 1, 3, 1, 5, 9, 4, 4, 5, 2, 7, 1, 9, 7, 3, 2,\n",
       "         8, 1, 2, 3, 5, 6, 9, 5]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(out, 1)[0].size()\n",
    "torch.max(out, 1)[1].size()\n",
    "torch.max(out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 8, 4, 8, 2, 5, 0, 3, 5, 1, 3, 1, 5, 7, 4, 4, 5, 2, 7, 1, 9, 7, 3, 2,\n",
       "        8, 1, 7, 3, 1, 6, 9, 5])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9709)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.1984, grad_fn=<AliasBackward>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.data[0] * label.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.198410987854004"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor.item(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-bd5b2a1a9647>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "torch.Tensor.item(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33333.333333\n"
     ]
    }
   ],
   "source": [
    "a = 100000/3\n",
    "print('{:.6f}'.format(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-169-b60042ec47b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "train_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6980, 0.3198, 0.0602, 0.9657],\n",
      "        [0.9098, 0.6337, 0.6436, 0.2291],\n",
      "        [0.6896, 0.1961, 0.1484, 0.5837],\n",
      "        [0.4911, 0.1785, 0.0305, 0.9112],\n",
      "        [0.0156, 0.3448, 0.5134, 0.3972]])\n",
      "torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.rand(5,3)\n",
    "x2 = torch.rand(5,1)\n",
    "\n",
    "x1 = Variable(x1)\n",
    "x2 = Variable(x2)\n",
    "\n",
    "x = torch.cat((x1,x2),1)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
