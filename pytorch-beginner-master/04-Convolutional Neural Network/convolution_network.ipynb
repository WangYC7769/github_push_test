{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:79: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1] Loss: 2.291740, Acc: 15.346354\n",
      "Finish 1 epoch, Loss: 2.268894, Acc: 27.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:122: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:128: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:131: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.136217, Acc: 51.800000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "# from logger import Logger\n",
    "\n",
    "# 定义超参数\n",
    "batch_size = 128\n",
    "learning_rate = 1e-2\n",
    "num_epoches = 1\n",
    "\n",
    "\n",
    "def to_np(x):\n",
    "    return x.cpu().data.numpy()\n",
    "\n",
    "\n",
    "# 下载训练集 MNIST 手写数字训练集\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# 定义 Convolution Network 模型\n",
    "class Cnn(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(Cnn, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, 6, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5, stride=1, padding=0),\n",
    "            nn.ReLU(), nn.MaxPool2d(2, 2))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(400, 120), nn.Linear(120, 84), nn.Linear(84, n_class))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "model = Cnn(1, 10)  # 图片大小是28x28\n",
    "\n",
    "use_gpu = torch.cuda.is_available()  # 判断是否有GPU加速\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "# 定义loss和optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# logger = Logger('./logs')\n",
    "\n",
    "# 开始训练\n",
    "for epoch in range(num_epoches):\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    print('*' * 10)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        img, label = data\n",
    "        if use_gpu:\n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        # 向前传播\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.data[0] * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        accuracy = (pred == label).float().mean()\n",
    "        running_acc += num_correct.data[0]\n",
    "        # 向后传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # ========================= Log ======================\n",
    "        \"\"\"\n",
    "        step = epoch * len(train_loader) + i\n",
    "        # (1) Log the scalar values\n",
    "        info = {'loss': loss.data[0], 'accuracy': accuracy.data[0]}\n",
    "        \n",
    "        \n",
    "        for tag, value in info.items():\n",
    "            logger.scalar_summary(tag, value, step)\n",
    "        \n",
    "        \n",
    "        # (2) Log values and gradients of the parameters (histogram)\n",
    "        for tag, value in model.named_parameters():\n",
    "            tag = tag.replace('.', '/')\n",
    "            logger.histo_summary(tag, to_np(value), step)\n",
    "            logger.histo_summary(tag + '/grad', to_np(value.grad), step)\n",
    "\n",
    "        # (3) Log the images\n",
    "        info = {'images': to_np(img.view(-1, 28, 28)[:10])}\n",
    "        \n",
    "        for tag, images in info.items():\n",
    "            logger.image_summary(tag, images, step)\n",
    "        \"\"\"\n",
    "        \n",
    "        if i % 300 == 0:\n",
    "            print('[{}/{}] Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "                epoch + 1, num_epoches, running_loss / (batch_size * i),\n",
    "                float(running_acc) *100 / (batch_size * i)))\n",
    "    print('Finish {} epoch, Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "        epoch + 1, running_loss / (len(train_dataset)), float(running_acc) *100 / (len(\n",
    "            train_dataset))))\n",
    "    model.eval()\n",
    "    eval_loss = 0.\n",
    "    eval_acc = 0.\n",
    "    for data in test_loader:\n",
    "        img, label = data\n",
    "        if use_gpu:\n",
    "            img = Variable(img, ).cuda()\n",
    "            label = Variable(label, volatile=True).cuda()\n",
    "        else:\n",
    "            img = Variable(img, volatile=True)\n",
    "            label = Variable(label, volatile=True)\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        eval_loss += loss.data[0] * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        eval_acc += num_correct.data[0]\n",
    "    print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(\n",
    "        test_dataset)), float(eval_acc) *100 / (len(test_dataset))))\n",
    "    print()\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), './cnn.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]]),\n",
       " tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "# from logger import Logger\n",
    "\n",
    "# 定义超参数\n",
    "batch_size = 128\n",
    "learning_rate = 1e-2\n",
    "num_epoches = 1\n",
    "\n",
    "\n",
    "def to_np(x):\n",
    "    return x.cpu().data.numpy()\n",
    "\n",
    "\n",
    "# 下载训练集 MNIST 手写数字训练集\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Cnn(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (1): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (2): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of Cnn(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (1): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (2): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nif torch.cuda.is_available():\\n    x = x.cuda()\\n    y = y.cuda()\\n    x + y\\n \\n# torch.Tensor(1,2,3) 与 torch.Tensor([1,2,3]) 的区别\\ntorch.Tensor(1,2,3) # 生成一个 shape 为 [1,2,3] 的 tensor\\ntorch.Tensor([1,2,3]) # 生成一个值为 [1,2,3] 的 tensor\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = a.copy()\n",
    "np.add(a, 1, out=a)\n",
    "print(a) # 如果a 变的话， b也会跟着变，说明b只是保存了一个地址而已，并没有深拷贝\n",
    "print(b) # Variable只是保存Tensor的地址，如果Tensor变的话，Variable也会跟着变\n",
    " \n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)# ndarray --> Tensor\n",
    "a_ = b.numpy() # Tensor --> ndarray\n",
    "np.add(a, 1, out=a)\n",
    "# 这个和 a = np.add(a,1)有什么区别呢？\n",
    "# a = np.add(a,1) 只是将a中保存的指针指向新计算好的数据上去\n",
    "# np.add(a, 1, out=a) 改变了a指向的数据\n",
    " \n",
    "# 将Tensor放到Cuda\n",
    "\"\"\"\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x + y\n",
    " \n",
    "# torch.Tensor(1,2,3) 与 torch.Tensor([1,2,3]) 的区别\n",
    "torch.Tensor(1,2,3) # 生成一个 shape 为 [1,2,3] 的 tensor\n",
    "torch.Tensor([1,2,3]) # 生成一个值为 [1,2,3] 的 tensor\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "# w1 = Variable(torch.Tensor([1.0,2.0,3.0]),requires_grad=True)#需要求导的话，requires_grad=True属性是必须的。\n",
    "# w2 = Variable(torch.Tensor([1.0,2.0,3.0]),requires_grad=True)\n",
    "\n",
    "w1 = torch.tensor([1.0,2.0,3.0],requires_grad=True)\n",
    "w2 = torch.tensor([1.0,2.0,3.0],requires_grad=True)\n",
    "print(w1.grad)\n",
    "print(w2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2., grad_fn=<MeanBackward1>)\n",
      "tensor([0.3333, 0.3333, 0.3333])\n",
      "tensor([0.6667, 0.6667, 0.6667])\n",
      "tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "d = torch.mean(w1) # d = 1/3 * w1\n",
    "print(d)\n",
    "d.backward()  # \n",
    "print(w1.grad)        #  dd/dw1 = 1/3\n",
    "d.backward()\n",
    "print(w1.grad) \n",
    "w1.grad.zero_()\n",
    "print(w1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'zero_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-d35696027f36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'zero_grad'"
     ]
    }
   ],
   "source": [
    "w1.grad.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3333, 0.3333, 0.3333])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1.0,2.0,3.0])\n",
    "a = Variable(a,requires_grad=True)\n",
    "b = torch.mean(a)\n",
    "b.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(img, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([54.])\n",
      "tensor([36.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1.0], requires_grad=True)\n",
    "b = torch.tensor([2.0], requires_grad=True)\n",
    "y = 3*a + 2*b +  2\n",
    "z = y**2\n",
    "\n",
    "z.backward()\n",
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv.0.weight', tensor([[[[-0.1226,  0.3009,  0.2670],\n",
       "                        [-0.1387,  0.1660, -0.2683],\n",
       "                        [ 0.3366, -0.2842,  0.1422]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3076,  0.2337, -0.2720],\n",
       "                        [ 0.2134, -0.2922, -0.1259],\n",
       "                        [ 0.3124,  0.1846, -0.2104]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0794,  0.1267,  0.3392],\n",
       "                        [-0.0820,  0.3822, -0.2643],\n",
       "                        [-0.2166,  0.3561, -0.2509]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2074,  0.0367, -0.2936],\n",
       "                        [-0.1242,  0.0315, -0.1952],\n",
       "                        [ 0.0009,  0.1570, -0.3235]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1062,  0.3189,  0.3042],\n",
       "                        [ 0.0501,  0.2080, -0.0133],\n",
       "                        [ 0.2097,  0.2451, -0.0345]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1718, -0.0173,  0.0249],\n",
       "                        [ 0.1059, -0.1863, -0.2994],\n",
       "                        [-0.2078, -0.2514, -0.1631]]]], device='cuda:0')),\n",
       "             ('conv.0.bias',\n",
       "              tensor([-0.0314, -0.2896,  0.3213,  0.2320,  0.1127,  0.2649], device='cuda:0')),\n",
       "             ('conv.3.weight',\n",
       "              tensor([[[[ 0.0112,  0.0848,  0.0274, -0.0127, -0.0039],\n",
       "                        [ 0.0716, -0.0124, -0.0440,  0.0489,  0.0431],\n",
       "                        [ 0.0154, -0.0211, -0.0735, -0.0705,  0.0649],\n",
       "                        [-0.0605, -0.0003, -0.0077, -0.0514,  0.0665],\n",
       "                        [-0.0787,  0.0731, -0.0148, -0.0736, -0.0257]],\n",
       "              \n",
       "                       [[ 0.0580, -0.0556, -0.0047, -0.0216,  0.0339],\n",
       "                        [ 0.0680, -0.0134,  0.0168,  0.0532, -0.0546],\n",
       "                        [-0.0566, -0.0378, -0.0614, -0.0215, -0.0713],\n",
       "                        [-0.0230, -0.0215,  0.0221, -0.0139,  0.0744],\n",
       "                        [ 0.0140,  0.0694,  0.0533,  0.0112,  0.0485]],\n",
       "              \n",
       "                       [[-0.0615, -0.0635, -0.0004, -0.0657,  0.0861],\n",
       "                        [ 0.0714, -0.0067,  0.0752,  0.0736, -0.0112],\n",
       "                        [-0.0329, -0.0039, -0.0393,  0.0823, -0.0435],\n",
       "                        [-0.0067, -0.0650, -0.0813,  0.0357, -0.0216],\n",
       "                        [-0.0270, -0.0566, -0.0557,  0.0636, -0.0414]],\n",
       "              \n",
       "                       [[-0.0733,  0.0009, -0.0054, -0.0720,  0.0091],\n",
       "                        [ 0.0632,  0.0653, -0.0637, -0.0846,  0.0599],\n",
       "                        [ 0.0321,  0.0817,  0.0309,  0.0752, -0.0290],\n",
       "                        [-0.0117, -0.0585,  0.0238, -0.0521,  0.0154],\n",
       "                        [ 0.0018,  0.0021,  0.0419,  0.0573, -0.0040]],\n",
       "              \n",
       "                       [[-0.0500,  0.0997,  0.0166,  0.0977,  0.0109],\n",
       "                        [ 0.0814,  0.0017,  0.0816,  0.0093,  0.0262],\n",
       "                        [-0.0182, -0.0584,  0.0595,  0.0346,  0.0797],\n",
       "                        [-0.0010, -0.0592, -0.0839, -0.0082, -0.0594],\n",
       "                        [-0.0626,  0.0557,  0.0403, -0.0594,  0.0487]],\n",
       "              \n",
       "                       [[ 0.0524, -0.0297,  0.0069,  0.0090, -0.0143],\n",
       "                        [ 0.0491, -0.0727,  0.0673, -0.0038,  0.0596],\n",
       "                        [ 0.0848, -0.0469,  0.0009,  0.0679, -0.0645],\n",
       "                        [ 0.0624,  0.0341,  0.0085, -0.0463, -0.0407],\n",
       "                        [-0.0671, -0.0480, -0.0809,  0.0742, -0.0147]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0714, -0.0814, -0.0517,  0.0047,  0.0619],\n",
       "                        [ 0.0018, -0.0624,  0.0586,  0.0706, -0.0288],\n",
       "                        [-0.0068,  0.0594, -0.0377,  0.0556,  0.0504],\n",
       "                        [ 0.0607, -0.0173, -0.0167,  0.0608,  0.0489],\n",
       "                        [-0.0542, -0.0088, -0.0355,  0.0221,  0.0698]],\n",
       "              \n",
       "                       [[-0.0088, -0.0790, -0.0141,  0.0324,  0.0372],\n",
       "                        [-0.0605,  0.0122,  0.0532, -0.0699,  0.0587],\n",
       "                        [ 0.0065, -0.0502, -0.0761,  0.0101, -0.0669],\n",
       "                        [ 0.0716,  0.0799, -0.0557, -0.0774, -0.0251],\n",
       "                        [-0.0230,  0.0384, -0.0112,  0.0109, -0.0483]],\n",
       "              \n",
       "                       [[-0.0146, -0.0682, -0.0377, -0.0234, -0.0650],\n",
       "                        [-0.0200,  0.0077,  0.0433, -0.0086,  0.0814],\n",
       "                        [-0.0773,  0.0302,  0.0251,  0.0845, -0.0468],\n",
       "                        [ 0.0123,  0.0904,  0.0029,  0.0561, -0.0716],\n",
       "                        [ 0.0636,  0.0810,  0.0413,  0.0520, -0.0123]],\n",
       "              \n",
       "                       [[-0.0473, -0.0427, -0.0110,  0.0378, -0.0415],\n",
       "                        [-0.0343, -0.0441, -0.0612,  0.0752,  0.0382],\n",
       "                        [-0.0717,  0.0162, -0.0812, -0.0039,  0.0244],\n",
       "                        [-0.0068, -0.0100,  0.0362, -0.0778,  0.0812],\n",
       "                        [-0.0268, -0.0344,  0.0151, -0.0738,  0.0845]],\n",
       "              \n",
       "                       [[ 0.0341, -0.0744,  0.0143,  0.0481, -0.0246],\n",
       "                        [-0.0573,  0.0281, -0.0704,  0.0532,  0.0175],\n",
       "                        [-0.0250,  0.0797, -0.0388, -0.0092,  0.0910],\n",
       "                        [ 0.0146,  0.0298,  0.0307,  0.0085, -0.0488],\n",
       "                        [-0.0550, -0.0649,  0.0182,  0.0637,  0.0158]],\n",
       "              \n",
       "                       [[ 0.0719,  0.0115,  0.0637, -0.0747,  0.0553],\n",
       "                        [-0.0410,  0.0772, -0.0740, -0.0634, -0.0655],\n",
       "                        [ 0.0126, -0.0439,  0.0758,  0.0098, -0.0020],\n",
       "                        [-0.0135,  0.0509, -0.0029,  0.0280, -0.0414],\n",
       "                        [ 0.0836, -0.0405, -0.0055,  0.0635,  0.0379]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0102, -0.0259,  0.0408,  0.0447, -0.0093],\n",
       "                        [ 0.0322, -0.0195, -0.0212, -0.0008,  0.0123],\n",
       "                        [-0.0733,  0.0410, -0.0735, -0.0057,  0.0183],\n",
       "                        [ 0.0310,  0.0551, -0.0516, -0.0522, -0.0715],\n",
       "                        [ 0.0494,  0.0373, -0.0461, -0.0318, -0.0590]],\n",
       "              \n",
       "                       [[ 0.0327,  0.0788,  0.0363,  0.0724,  0.0167],\n",
       "                        [-0.0494,  0.0508,  0.0200,  0.0759,  0.0674],\n",
       "                        [ 0.0584, -0.0304,  0.0662,  0.0452, -0.0368],\n",
       "                        [-0.0609,  0.0116, -0.0261, -0.0164, -0.0503],\n",
       "                        [ 0.0263,  0.0298,  0.0491,  0.0366, -0.0652]],\n",
       "              \n",
       "                       [[-0.0119, -0.0184, -0.0771,  0.0518,  0.0958],\n",
       "                        [-0.0231,  0.0130, -0.0575, -0.0107,  0.0766],\n",
       "                        [ 0.0222, -0.0742,  0.0653, -0.0471,  0.0411],\n",
       "                        [ 0.0179,  0.0203,  0.0317, -0.0233, -0.0842],\n",
       "                        [ 0.0762,  0.0502,  0.0833, -0.0475, -0.0413]],\n",
       "              \n",
       "                       [[ 0.0430, -0.0290, -0.0250, -0.0010, -0.0793],\n",
       "                        [ 0.0548, -0.0365,  0.0559,  0.0049,  0.0464],\n",
       "                        [ 0.0591,  0.0241, -0.0424,  0.0756,  0.0820],\n",
       "                        [-0.0808,  0.0786,  0.0501,  0.0739,  0.0409],\n",
       "                        [ 0.0015,  0.0174,  0.0002, -0.0258,  0.0731]],\n",
       "              \n",
       "                       [[ 0.0317, -0.0356, -0.0420, -0.0511,  0.1019],\n",
       "                        [-0.0724, -0.0501,  0.0491,  0.0227,  0.0491],\n",
       "                        [ 0.0234,  0.0264, -0.0283, -0.0015,  0.0034],\n",
       "                        [-0.0181, -0.0103, -0.0458,  0.0697, -0.0019],\n",
       "                        [ 0.0932,  0.0490, -0.0537, -0.0555, -0.0202]],\n",
       "              \n",
       "                       [[ 0.0220, -0.0315,  0.0597, -0.0558, -0.0292],\n",
       "                        [ 0.0415,  0.0162, -0.0696,  0.0132, -0.0673],\n",
       "                        [ 0.0696,  0.0314,  0.0573,  0.0163,  0.0057],\n",
       "                        [ 0.0059, -0.0743,  0.0252,  0.0093,  0.0720],\n",
       "                        [ 0.0240, -0.0077,  0.0206, -0.0521, -0.0651]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0546,  0.0135, -0.0794,  0.0483, -0.0561],\n",
       "                        [-0.0581, -0.0739, -0.0778,  0.0732, -0.0521],\n",
       "                        [-0.0475, -0.0271, -0.0631, -0.0572, -0.0525],\n",
       "                        [ 0.0486,  0.0542,  0.0450,  0.0547, -0.0706],\n",
       "                        [-0.0630, -0.0706,  0.0797, -0.0134,  0.0555]],\n",
       "              \n",
       "                       [[-0.0203, -0.0197, -0.0476, -0.0541, -0.0005],\n",
       "                        [ 0.0625, -0.0394,  0.0506, -0.0503,  0.0615],\n",
       "                        [-0.0685, -0.0284, -0.0165,  0.0124,  0.0139],\n",
       "                        [ 0.0531,  0.0367,  0.0686, -0.0079,  0.0322],\n",
       "                        [-0.0500,  0.0095, -0.0385,  0.0338, -0.0429]],\n",
       "              \n",
       "                       [[-0.0164, -0.0461, -0.0102, -0.0475,  0.0635],\n",
       "                        [ 0.0765, -0.0315, -0.0751,  0.0092, -0.0563],\n",
       "                        [-0.0392, -0.0002, -0.0646, -0.0579,  0.0332],\n",
       "                        [-0.0783, -0.0640, -0.0355,  0.0750,  0.0631],\n",
       "                        [-0.0559, -0.0366,  0.0348, -0.0222, -0.0221]],\n",
       "              \n",
       "                       [[-0.0761, -0.0797,  0.0575, -0.0784, -0.0629],\n",
       "                        [ 0.0820, -0.0057, -0.0606,  0.0098,  0.0595],\n",
       "                        [ 0.0698, -0.0106, -0.0118,  0.0673,  0.0618],\n",
       "                        [-0.0024,  0.0789,  0.0508,  0.0131, -0.0810],\n",
       "                        [-0.0591, -0.0428, -0.0781, -0.0569, -0.0711]],\n",
       "              \n",
       "                       [[ 0.0408,  0.0051,  0.0102, -0.0565, -0.0573],\n",
       "                        [ 0.0616,  0.0408, -0.0362,  0.0271,  0.0523],\n",
       "                        [ 0.0593, -0.0575,  0.0770,  0.0734, -0.0730],\n",
       "                        [-0.0149, -0.0809,  0.0328,  0.0649,  0.0488],\n",
       "                        [ 0.0675, -0.0036, -0.0554, -0.0001,  0.0820]],\n",
       "              \n",
       "                       [[ 0.0730, -0.0694,  0.0498,  0.0642, -0.0169],\n",
       "                        [-0.0660, -0.0730,  0.0098,  0.0775, -0.0610],\n",
       "                        [-0.0744,  0.0472,  0.0626, -0.0076, -0.0294],\n",
       "                        [-0.0229, -0.0625,  0.0122, -0.0204,  0.0707],\n",
       "                        [-0.0249,  0.0186, -0.0243,  0.0145,  0.0009]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0042,  0.0243,  0.0441,  0.0224,  0.0674],\n",
       "                        [-0.0663, -0.0717, -0.0006, -0.0684,  0.0568],\n",
       "                        [ 0.0210,  0.0260, -0.0593,  0.0017,  0.0104],\n",
       "                        [-0.0089,  0.0084, -0.0218, -0.0047,  0.0184],\n",
       "                        [ 0.0464, -0.0176,  0.0308, -0.0399, -0.0774]],\n",
       "              \n",
       "                       [[-0.0308, -0.0086,  0.0743, -0.0737,  0.0643],\n",
       "                        [-0.0506, -0.0095, -0.0430, -0.0172, -0.0664],\n",
       "                        [-0.0130,  0.0740, -0.0734, -0.0170, -0.0018],\n",
       "                        [-0.0638, -0.0202, -0.0058,  0.0205,  0.0492],\n",
       "                        [-0.0107, -0.0240, -0.0651,  0.0132,  0.0605]],\n",
       "              \n",
       "                       [[ 0.0749, -0.0162, -0.0810,  0.0681, -0.0286],\n",
       "                        [-0.0566,  0.0582,  0.0185, -0.0348, -0.0165],\n",
       "                        [ 0.0792, -0.0745, -0.0251, -0.0006, -0.0542],\n",
       "                        [-0.0010,  0.0240,  0.0814, -0.0192,  0.0342],\n",
       "                        [-0.0606, -0.0452,  0.0467, -0.0607, -0.0173]],\n",
       "              \n",
       "                       [[-0.0494, -0.0497,  0.0649, -0.0225,  0.0089],\n",
       "                        [ 0.0404, -0.0464, -0.0121,  0.0625, -0.0306],\n",
       "                        [ 0.0211,  0.0640,  0.0050, -0.0169, -0.0397],\n",
       "                        [-0.0170, -0.0441, -0.0786, -0.0221,  0.0719],\n",
       "                        [ 0.0654, -0.0662, -0.0705,  0.0672,  0.0433]],\n",
       "              \n",
       "                       [[ 0.0688, -0.0542, -0.0838,  0.0419, -0.0599],\n",
       "                        [ 0.0585,  0.0170,  0.0283, -0.0059,  0.0177],\n",
       "                        [ 0.0531,  0.0103,  0.0001,  0.0558, -0.0023],\n",
       "                        [ 0.0082,  0.0304, -0.0436, -0.0572, -0.0023],\n",
       "                        [-0.0840, -0.0467,  0.0770,  0.0550, -0.0431]],\n",
       "              \n",
       "                       [[-0.0123, -0.0387,  0.0590, -0.0146,  0.0798],\n",
       "                        [ 0.0685, -0.0277,  0.0097,  0.0076, -0.0530],\n",
       "                        [-0.0426, -0.0591, -0.0252, -0.0069,  0.0235],\n",
       "                        [-0.0658, -0.0497, -0.0001, -0.0444, -0.0467],\n",
       "                        [-0.0202, -0.0620,  0.0215, -0.0347, -0.0774]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0786, -0.0456, -0.0617,  0.0306,  0.0730],\n",
       "                        [ 0.0815,  0.0364, -0.0428,  0.0015,  0.0559],\n",
       "                        [ 0.0285,  0.0298,  0.0817, -0.0507, -0.0538],\n",
       "                        [ 0.0812,  0.0267, -0.0702,  0.0482,  0.0586],\n",
       "                        [-0.0631,  0.0390,  0.0437,  0.0398, -0.0467]],\n",
       "              \n",
       "                       [[-0.0794,  0.0071, -0.0770,  0.0748, -0.0043],\n",
       "                        [ 0.0435,  0.0245, -0.0092,  0.0561,  0.0510],\n",
       "                        [ 0.0062,  0.0223, -0.0245, -0.0557,  0.0513],\n",
       "                        [ 0.0091, -0.0480, -0.0039, -0.0017,  0.0213],\n",
       "                        [-0.0418,  0.0595, -0.0046, -0.0244, -0.0382]],\n",
       "              \n",
       "                       [[ 0.0340, -0.0779, -0.0476, -0.0035, -0.0519],\n",
       "                        [ 0.0032, -0.0360, -0.0259, -0.0191,  0.0230],\n",
       "                        [ 0.0211,  0.0756, -0.0666, -0.0514,  0.0818],\n",
       "                        [ 0.0478,  0.0334, -0.0128,  0.0279, -0.0556],\n",
       "                        [-0.0201,  0.0400, -0.0004, -0.0762,  0.0816]],\n",
       "              \n",
       "                       [[-0.0542, -0.0621, -0.0770, -0.0113,  0.0172],\n",
       "                        [-0.0084,  0.0407, -0.0526, -0.0037,  0.0711],\n",
       "                        [-0.0203,  0.0239,  0.0062, -0.0375, -0.0376],\n",
       "                        [ 0.0446,  0.0654, -0.0495, -0.0429, -0.0325],\n",
       "                        [ 0.0183, -0.0542, -0.0442,  0.0205,  0.0559]],\n",
       "              \n",
       "                       [[-0.0233, -0.0366,  0.0066, -0.0423, -0.0616],\n",
       "                        [-0.0366,  0.0570,  0.0525, -0.0624, -0.0679],\n",
       "                        [ 0.0630,  0.0042, -0.0467, -0.0298, -0.0437],\n",
       "                        [ 0.0802, -0.0143,  0.0486,  0.0000,  0.0016],\n",
       "                        [-0.0078, -0.0178, -0.0046,  0.0282,  0.0177]],\n",
       "              \n",
       "                       [[-0.0536, -0.0194,  0.0235, -0.0126, -0.0197],\n",
       "                        [-0.0047, -0.0522,  0.0026,  0.0244, -0.0746],\n",
       "                        [ 0.0809,  0.0341, -0.0253, -0.0462, -0.0144],\n",
       "                        [-0.0499,  0.0711,  0.0111, -0.0691, -0.0164],\n",
       "                        [ 0.0065, -0.0031,  0.0233, -0.0036, -0.0380]]]], device='cuda:0')),\n",
       "             ('conv.3.bias',\n",
       "              tensor([ 0.0758,  0.0695, -0.0208,  0.0666, -0.0092,  0.0273,  0.0196,  0.0064,\n",
       "                      -0.0019,  0.0108,  0.0662, -0.0560,  0.0055,  0.0258,  0.0375,  0.0003],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.0.weight',\n",
       "              tensor([[ 0.0293, -0.0031, -0.0198,  ..., -0.0191, -0.0173, -0.0460],\n",
       "                      [-0.0304,  0.0014, -0.0180,  ...,  0.0429,  0.0138,  0.0354],\n",
       "                      [-0.0409,  0.0386, -0.0102,  ...,  0.0228, -0.0264, -0.0253],\n",
       "                      ...,\n",
       "                      [ 0.0345, -0.0157,  0.0264,  ...,  0.0088,  0.0006, -0.0302],\n",
       "                      [ 0.0266, -0.0436,  0.0020,  ...,  0.0398,  0.0331,  0.0005],\n",
       "                      [-0.0114, -0.0457,  0.0102,  ..., -0.0495,  0.0106, -0.0040]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.0.bias',\n",
       "              tensor([-0.0037,  0.0199, -0.0135, -0.0276, -0.0406, -0.0426,  0.0068, -0.0179,\n",
       "                      -0.0038, -0.0338,  0.0084, -0.0407,  0.0204,  0.0309, -0.0282, -0.0011,\n",
       "                       0.0416,  0.0125, -0.0201, -0.0398,  0.0430,  0.0221,  0.0288, -0.0081,\n",
       "                      -0.0304,  0.0223, -0.0133, -0.0409,  0.0037,  0.0080, -0.0261, -0.0445,\n",
       "                      -0.0285,  0.0309, -0.0198,  0.0233, -0.0137,  0.0334,  0.0528,  0.0131,\n",
       "                      -0.0103,  0.0336, -0.0276,  0.0481, -0.0335,  0.0416,  0.0266,  0.0158,\n",
       "                      -0.0449, -0.0151,  0.0398,  0.0270, -0.0412, -0.0394,  0.0087,  0.0092,\n",
       "                      -0.0479,  0.0201,  0.0058,  0.0159, -0.0020,  0.0483, -0.0320,  0.0321,\n",
       "                       0.0251,  0.0199,  0.0137, -0.0323,  0.0162, -0.0430, -0.0422,  0.0263,\n",
       "                      -0.0351,  0.0035, -0.0446, -0.0404,  0.0284, -0.0226, -0.0103, -0.0273,\n",
       "                       0.0035, -0.0043,  0.0026, -0.0535, -0.0354, -0.0266,  0.0411,  0.0245,\n",
       "                      -0.0055,  0.0405, -0.0415, -0.0514,  0.0219, -0.0171,  0.0392,  0.0424,\n",
       "                      -0.0294, -0.0104, -0.0252, -0.0358,  0.0437,  0.0427,  0.0178,  0.0189,\n",
       "                      -0.0173,  0.0174, -0.0034,  0.0069,  0.0076,  0.0176,  0.0003,  0.0079,\n",
       "                       0.0418, -0.0129, -0.0175,  0.0104, -0.0374,  0.0303, -0.0044, -0.0026],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.1.weight',\n",
       "              tensor([[-0.0337,  0.0819,  0.0774,  ..., -0.0079,  0.0263,  0.0437],\n",
       "                      [ 0.0095,  0.0590,  0.0813,  ...,  0.0794,  0.0052, -0.0433],\n",
       "                      [ 0.0745,  0.0679,  0.0769,  ..., -0.0227, -0.0616,  0.0483],\n",
       "                      ...,\n",
       "                      [ 0.0521,  0.0867,  0.0724,  ..., -0.0700, -0.0818, -0.0101],\n",
       "                      [-0.0334,  0.0554,  0.0723,  ...,  0.0412,  0.0377,  0.0238],\n",
       "                      [ 0.0075, -0.0459, -0.0271,  ...,  0.0014, -0.0095, -0.0872]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.1.bias',\n",
       "              tensor([-0.0751, -0.0337, -0.0581, -0.0626, -0.0582, -0.0673,  0.0005, -0.0834,\n",
       "                       0.0457,  0.0683,  0.0893, -0.0683, -0.0834,  0.0790,  0.0375,  0.0763,\n",
       "                       0.0044,  0.0717,  0.0890, -0.0600, -0.0060, -0.0320,  0.0899,  0.0694,\n",
       "                       0.0420,  0.0280,  0.0667,  0.0138, -0.0060,  0.0546, -0.0970, -0.0712,\n",
       "                      -0.0875,  0.0754, -0.0781,  0.0780,  0.0212, -0.0111, -0.0631, -0.0065,\n",
       "                      -0.0674,  0.0786, -0.0763,  0.0469, -0.0264, -0.0010, -0.0746, -0.0355,\n",
       "                      -0.0594,  0.0678, -0.0269, -0.0040, -0.0653, -0.0599,  0.0659, -0.0346,\n",
       "                       0.0637, -0.0079,  0.0034, -0.0149,  0.0652,  0.0835, -0.0657,  0.0257,\n",
       "                      -0.0447, -0.0156,  0.0117, -0.0400, -0.0201, -0.0546, -0.0483, -0.0045,\n",
       "                      -0.0696, -0.0429,  0.0831,  0.0107, -0.0484,  0.0609, -0.0143,  0.0827,\n",
       "                       0.0843, -0.0770,  0.0245, -0.0550], device='cuda:0')),\n",
       "             ('fc.2.weight',\n",
       "              tensor([[ 0.0752,  0.1036,  0.0464,  0.0363, -0.0762,  0.0531,  0.0098,  0.0027,\n",
       "                       -0.0968,  0.0209,  0.0090, -0.0512, -0.0026,  0.0515,  0.0703, -0.0373,\n",
       "                       -0.0657, -0.0873, -0.0031,  0.0732, -0.0506,  0.0076,  0.0551,  0.0033,\n",
       "                        0.0924, -0.0735,  0.0728,  0.0869,  0.1010, -0.0395,  0.0156, -0.0527,\n",
       "                        0.1060, -0.0458, -0.1161, -0.0560, -0.0896, -0.0665, -0.0183, -0.0586,\n",
       "                       -0.0029, -0.0374,  0.0481, -0.0272,  0.0621, -0.0686, -0.0692,  0.0534,\n",
       "                       -0.0137,  0.0343,  0.0478, -0.0660,  0.0780, -0.0182,  0.0906, -0.0484,\n",
       "                       -0.0034, -0.0336, -0.0890,  0.0138,  0.0707,  0.0700,  0.0002,  0.0045,\n",
       "                       -0.0384,  0.0123,  0.1080, -0.0674,  0.0492,  0.0429, -0.0512,  0.0061,\n",
       "                        0.1078, -0.0556, -0.1038, -0.0427,  0.0229,  0.0286,  0.0705,  0.0778,\n",
       "                       -0.0920, -0.1056,  0.0329, -0.0327],\n",
       "                      [ 0.1062, -0.0423,  0.0407,  0.0217,  0.0667, -0.0767, -0.0329, -0.0165,\n",
       "                       -0.0178,  0.0763, -0.0194, -0.0841, -0.1102, -0.0197,  0.0248,  0.0851,\n",
       "                       -0.0539, -0.0508, -0.0274, -0.0649,  0.1095,  0.0628,  0.1018, -0.0063,\n",
       "                        0.1092,  0.0565, -0.0071, -0.0673,  0.0707,  0.0908, -0.0763,  0.0555,\n",
       "                       -0.0992,  0.0917, -0.0448,  0.0136,  0.0713, -0.1034, -0.0041, -0.0909,\n",
       "                        0.0100,  0.0036, -0.0429, -0.0931, -0.0491,  0.0293, -0.0085, -0.0402,\n",
       "                        0.0660,  0.0865, -0.0940, -0.0598,  0.0574,  0.0658,  0.0845,  0.1227,\n",
       "                        0.0979, -0.0795, -0.0325,  0.1139, -0.0048,  0.0064, -0.0637,  0.0990,\n",
       "                       -0.0077, -0.0474, -0.0675,  0.0566, -0.0473, -0.1091,  0.0062, -0.0860,\n",
       "                       -0.0857,  0.0554, -0.0487, -0.0941, -0.0195, -0.0979, -0.0055, -0.0798,\n",
       "                        0.0850,  0.1122,  0.0184, -0.0493],\n",
       "                      [-0.0987, -0.0552,  0.0317,  0.1041, -0.0757,  0.0822, -0.0205,  0.0760,\n",
       "                       -0.0792, -0.0556,  0.0219, -0.0960, -0.1103,  0.0738,  0.0329,  0.1107,\n",
       "                        0.1016,  0.0394, -0.0758,  0.0819, -0.1027, -0.0615,  0.0216,  0.1042,\n",
       "                        0.0979,  0.0092,  0.0673, -0.0229, -0.0026, -0.0973,  0.1048, -0.0325,\n",
       "                       -0.1119,  0.0587, -0.0543, -0.1102,  0.0518,  0.0207, -0.0976,  0.0762,\n",
       "                        0.0095, -0.0026,  0.0437,  0.0858, -0.0198,  0.0223, -0.0473, -0.0774,\n",
       "                       -0.1035, -0.0278, -0.0270, -0.1045, -0.1094,  0.0165, -0.0027, -0.0205,\n",
       "                        0.0607,  0.0586,  0.0134,  0.0846,  0.0597, -0.1008, -0.0066, -0.0252,\n",
       "                       -0.0813, -0.0148,  0.0225, -0.0756, -0.0604,  0.0911, -0.0615, -0.0778,\n",
       "                        0.0845, -0.0396, -0.0641,  0.0725,  0.0195, -0.0031,  0.1010,  0.0711,\n",
       "                       -0.0117,  0.0199,  0.0924,  0.0297],\n",
       "                      [ 0.0073, -0.0949,  0.1035,  0.0151, -0.0170, -0.0501,  0.1037, -0.0865,\n",
       "                        0.0159, -0.1065, -0.0539,  0.0693,  0.0317,  0.0334, -0.0005,  0.0744,\n",
       "                        0.0946,  0.0724, -0.0638,  0.0717, -0.1128, -0.0778, -0.0482,  0.0573,\n",
       "                       -0.0725,  0.0719,  0.0620,  0.0443, -0.0952, -0.0480,  0.0477, -0.0430,\n",
       "                        0.0249,  0.0991, -0.0714, -0.0066,  0.0900,  0.0798,  0.0943,  0.0964,\n",
       "                       -0.0574, -0.0001,  0.0396,  0.0891, -0.0571, -0.0046, -0.0645, -0.0523,\n",
       "                        0.0046, -0.0045,  0.0524,  0.0909, -0.0641, -0.0407,  0.0858,  0.0393,\n",
       "                       -0.0097,  0.0866, -0.0606,  0.0913,  0.0699,  0.0846,  0.0942, -0.0365,\n",
       "                        0.0738,  0.0789, -0.0672, -0.0689,  0.0201, -0.0721, -0.0445,  0.0155,\n",
       "                       -0.0728, -0.0884, -0.0857, -0.1013,  0.0347,  0.0245, -0.0264, -0.0579,\n",
       "                        0.0419,  0.0835, -0.0949, -0.0621],\n",
       "                      [-0.0608,  0.0807,  0.0250,  0.0560,  0.0645, -0.1061,  0.0532, -0.0670,\n",
       "                       -0.1019, -0.1080,  0.0984,  0.0823,  0.0211,  0.0390,  0.0520, -0.0408,\n",
       "                        0.0014, -0.0561, -0.0871, -0.0220, -0.0812,  0.1095, -0.0760,  0.0656,\n",
       "                       -0.0695, -0.0602, -0.0894,  0.0769, -0.0485,  0.0673,  0.0853, -0.0821,\n",
       "                       -0.0024, -0.0375,  0.0002,  0.1146, -0.0177, -0.0053,  0.1093, -0.0313,\n",
       "                        0.0426, -0.0103,  0.0315, -0.0762,  0.0200, -0.0323, -0.0175, -0.0962,\n",
       "                       -0.0993, -0.0339,  0.0325,  0.0509,  0.0897, -0.0366, -0.0622,  0.0658,\n",
       "                        0.1105,  0.0129, -0.1079, -0.0567, -0.0201, -0.0629, -0.0842, -0.0634,\n",
       "                       -0.0347, -0.1167,  0.0650, -0.0470,  0.0913,  0.0401, -0.0374, -0.0741,\n",
       "                       -0.1147,  0.0251, -0.0323, -0.1040, -0.0129,  0.0576, -0.0939,  0.0084,\n",
       "                        0.0938, -0.0580, -0.0491,  0.0242],\n",
       "                      [-0.0520,  0.0652,  0.0263, -0.0689,  0.0769,  0.0021, -0.1002, -0.0550,\n",
       "                       -0.0042, -0.0888, -0.0904,  0.0453,  0.0442, -0.0842,  0.0812,  0.0100,\n",
       "                       -0.0195, -0.1011, -0.0710,  0.0450, -0.0063, -0.0040, -0.0447,  0.0308,\n",
       "                        0.0376,  0.0356, -0.0063,  0.0142, -0.0628, -0.0646,  0.0336, -0.0898,\n",
       "                       -0.0040,  0.0350,  0.0562,  0.0276,  0.0579, -0.0197,  0.0764, -0.0038,\n",
       "                       -0.0396, -0.0628,  0.0026, -0.0395,  0.0979,  0.1138, -0.0647,  0.0271,\n",
       "                        0.0705, -0.0501, -0.0910,  0.0331,  0.1067, -0.0521,  0.0096,  0.0126,\n",
       "                        0.0734,  0.1032,  0.0777,  0.0571,  0.1033,  0.0312, -0.0334,  0.0949,\n",
       "                       -0.0705, -0.0483, -0.0030,  0.0633,  0.0519,  0.0694, -0.0196, -0.0058,\n",
       "                       -0.0183, -0.0555,  0.0409,  0.0121, -0.0516,  0.0378,  0.0156, -0.1123,\n",
       "                        0.0221, -0.0632, -0.0376, -0.0437],\n",
       "                      [-0.0319, -0.0817,  0.0786,  0.0584,  0.0784, -0.1117,  0.0099,  0.0981,\n",
       "                        0.0220,  0.0746,  0.0726,  0.0746,  0.0932,  0.0576, -0.0478,  0.0263,\n",
       "                        0.0280, -0.0271, -0.0144, -0.0518,  0.0814,  0.0611, -0.0188,  0.0255,\n",
       "                       -0.0247,  0.0869, -0.0599, -0.1081,  0.0250,  0.0434,  0.0768, -0.0509,\n",
       "                       -0.0476, -0.0772, -0.0832, -0.0081,  0.1002, -0.0014,  0.0051,  0.0477,\n",
       "                        0.0946, -0.0010, -0.0484,  0.0715, -0.0909, -0.0809, -0.0251,  0.0024,\n",
       "                        0.0899,  0.0092,  0.0221,  0.0472,  0.0626, -0.0934, -0.0710, -0.0076,\n",
       "                        0.0246,  0.0042,  0.0579,  0.0572, -0.0033,  0.0933, -0.0908, -0.0656,\n",
       "                        0.0140, -0.0750,  0.1069,  0.0409,  0.0620,  0.0639, -0.0355, -0.0323,\n",
       "                       -0.0959, -0.0086,  0.0516, -0.0481, -0.0658,  0.0144,  0.0906, -0.0242,\n",
       "                       -0.0890, -0.0527,  0.0850,  0.0912],\n",
       "                      [ 0.0952, -0.0430, -0.0372,  0.0445, -0.0223,  0.0495, -0.0800, -0.1060,\n",
       "                        0.0692,  0.0826,  0.0606,  0.0336,  0.1100,  0.0700, -0.0050,  0.0850,\n",
       "                       -0.0841,  0.0488, -0.0848,  0.0752,  0.0683, -0.0206, -0.0134,  0.0836,\n",
       "                       -0.0711,  0.0234, -0.0402, -0.0330, -0.0075, -0.0448,  0.0165,  0.0752,\n",
       "                        0.0535,  0.0968,  0.0260, -0.0786, -0.0431,  0.0906,  0.0972,  0.0945,\n",
       "                        0.0035,  0.0153, -0.0497,  0.0188,  0.0794, -0.0337,  0.0508, -0.0985,\n",
       "                        0.0917,  0.0854, -0.0398, -0.0366, -0.0118,  0.1088,  0.0575,  0.0388,\n",
       "                       -0.0250, -0.0828,  0.1037, -0.0340, -0.0328,  0.0988,  0.0014, -0.0539,\n",
       "                       -0.0560,  0.0892, -0.0645, -0.0966,  0.0079,  0.0725, -0.0019, -0.0976,\n",
       "                        0.0511, -0.0125,  0.0473, -0.0179,  0.0423, -0.0344, -0.0187, -0.0714,\n",
       "                       -0.0825,  0.0886, -0.0914,  0.0427],\n",
       "                      [ 0.0184, -0.0016, -0.0258, -0.0910,  0.0250, -0.1050, -0.0286,  0.1055,\n",
       "                        0.0635, -0.0953, -0.1059, -0.0280, -0.0638,  0.0621,  0.0895,  0.0839,\n",
       "                        0.0722, -0.1070, -0.0954,  0.1117, -0.0676, -0.0389, -0.1096,  0.0184,\n",
       "                        0.0293, -0.0475,  0.0835,  0.0855, -0.0690, -0.0661,  0.0258,  0.0076,\n",
       "                        0.0660, -0.1077,  0.0238, -0.0265, -0.1082, -0.0915,  0.0977,  0.0654,\n",
       "                       -0.0170, -0.0279,  0.0017, -0.0540, -0.0155,  0.0829, -0.0718, -0.1092,\n",
       "                        0.0462, -0.0665,  0.1079, -0.0619,  0.0529,  0.0041, -0.0995, -0.0560,\n",
       "                       -0.0215, -0.0800, -0.0817,  0.1034,  0.0208, -0.1089, -0.0596,  0.0828,\n",
       "                        0.0311, -0.0834,  0.0413, -0.0355, -0.0260,  0.0830,  0.0693,  0.1091,\n",
       "                       -0.0156,  0.1169,  0.0777, -0.0012, -0.0102, -0.1105,  0.0397,  0.1026,\n",
       "                        0.0784,  0.0961, -0.0601,  0.1074],\n",
       "                      [ 0.0205, -0.1076,  0.0843,  0.0073,  0.0378,  0.0230,  0.1050,  0.0014,\n",
       "                       -0.0865, -0.0036,  0.1147, -0.0123, -0.0142, -0.0645, -0.0497,  0.0978,\n",
       "                        0.0092, -0.0314, -0.0421, -0.0148,  0.0574, -0.0435, -0.0269,  0.0415,\n",
       "                       -0.0418, -0.1032,  0.0164, -0.0676,  0.0234, -0.0571, -0.0695,  0.0036,\n",
       "                       -0.0432, -0.1111,  0.0783, -0.0902, -0.0235, -0.0807, -0.0350,  0.0753,\n",
       "                       -0.0542,  0.0568, -0.0043, -0.0743,  0.0132, -0.0749,  0.1129,  0.0983,\n",
       "                        0.0194, -0.0645,  0.0765, -0.0286, -0.0185, -0.1060,  0.0355, -0.0318,\n",
       "                        0.0939,  0.0941,  0.0180,  0.0267,  0.0948, -0.0062, -0.0592,  0.0630,\n",
       "                       -0.0933,  0.0097, -0.0029,  0.0586, -0.0423, -0.0807, -0.0935,  0.0780,\n",
       "                       -0.0764, -0.0986, -0.0728, -0.1082,  0.0879, -0.1059,  0.0291, -0.0623,\n",
       "                        0.0161,  0.0615, -0.0868,  0.0303]], device='cuda:0')),\n",
       "             ('fc.2.bias',\n",
       "              tensor([-0.0361, -0.0181, -0.0969, -0.0371, -0.0123,  0.0263, -0.0907,  0.0609,\n",
       "                       0.0008, -0.0530], device='cuda:0'))])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.randn(5, 5))\n",
    "y = Variable(torch.randn(5, 5))\n",
    "z = Variable(torch.randn(5, 5), requires_grad=True)\n",
    "a = x + y # x, y的 requires_grad的标记都为false， 所以输出的变量requires_grad也为false\n",
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = x + z #a ,z 中，有一个 requires_grad 的标记为True，那么输出的变量的 requires_grad为True\n",
    "b.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\dell/.torch\\models\\resnet18-5c106cde.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "model = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
